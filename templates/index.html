<!doctype html>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Hash Archive</title>
<link rel="stylesheet" type="text/css" href="/index.css">

<h1 class="margin">Hash Archive <sup>(beta)</sup></h1>

<form class="lookup margin" method="post" action="./lookup">
<label>URL or hash:</label>
<div class="field wrap"><input type="text" name="str"></div>
<div class="submit wrap"><input type="submit" value="Lookup"></div>
</form>

<div class="entry margin">
Example lookups
<ul id="examples">
<li><a href="https://tools.ietf.org/html/rfc3986">Web URL</a>: {{web-url-example}}
<li><a href="https://github.com/hash-uri/hash-uri">Hash URI</a>: {{hash-uri-example}}
<li><a href="https://tools.ietf.org/html/rfc6920">Named Info</a>: {{named-info-example}}
<li><a href="https://github.com/jbenet/multihash">MultiHash</a>: {{multihash-example}}
<li><a href="https://www.w3.org/TR/SRI">Subresource Integrity</a>: {{prefix-example}}
<li><a href="https://github.com/ssbc/docs/blob/master/ssb/linking.md">SSB</a>: {{ssb-example}}
<li><a href="http://magnet-uri.sourceforge.net/">Magnet URI</a>: {{magnet-example}}
</ul>
</div>

<div class="entry margin">
Recently fetched URLs
<ul id="recent-list">{{recent-list}}</ul>
</div>

<div class="entry margin">
<div><a href="/critical/">Critical URLs</a></div>
<p>Examples:</p>
<ul id="critical-list">{{critical-list}}</ul>
</div>

<div class="entry margin">
<div>About</div>
<p>I made this site because so many Linux distributions still don't provide easy+secure download options in <code>$YEAR</code>. Using this archive (and hopefully other sources), you can have at least a small amount of confidence in the authenticity of your ISOs. Just put in the URL of the ISO, torrent file, or any other HTTP (or HTTPS) resource and we'll request the file and compute the hash for you using a wide variety of algorithms.</p>

<p>For sites that don't support HTTPS, this is a little bit like domain validation for certificates. Unless someone can intercept your local traffic <i>and</i> our traffic to a site, you'll be able to spot <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack">MITM attacks</a>. This level of security isn't great, but it's better than nothing.</p>

<p>For sites that <i>do</i> support HTTPS, validating hashes from a third party is still useful. It can tell you if the server was compromised (like <a href="http://blog.linuxmint.com/?p=2994">Linux Mint recently</a>) or if the site is trying to make stealth updates (like on political campaign sites). This is a little bit like <a href="https://www.certificate-transparency.org/">Certificate Transparency</a>, or, of course, the Internet Archive's <a href="https://archive.org/web/">Wayback Machine</a>.</p>

<p>You can also do reverse lookups to find out what URLs provide (or used to provide) a given hash. This might be useful for finding mirrors (although it only works if we've previously crawled those URLs).</p>

<ul>
<li><a href="javascript:void(open(&quot;http://localhost:8000/history/&quot;+document.location))">Bookmarklet (right click and choose "bookmark this link")</a>
<li><a href="./database.sql.gz">Download the latest database snapshot</a>
<li><a href="https://github.com/btrask/hash-archive">Site source code</a>
</ul>
</div>

<div class="entry margin">
<div>FAQ</div>

<p><b>What kind of questions can Hash Archive answer?</b></p>
<p>It can answer questions such as:</p>
<ul>
<li>Was this file downloaded from that URL?
<li>Did this URL provide the same file last week?
<li>Does this URL provide the same file to other clients?
<li>What mirrors are available for this URL?
<li>Where did this file come from?
</ul>

<p><b>How can I compute and verify my own hashes?</b></p>
<p>There are several options:</p>
<ul>
<li>Hash URIs (CLI): use <a href="https://github.com/hash-uri/hash-uri/tree/master/cli">hash-uri</a>, which can compute hashes and do validation for you
<li>MultiHash (CLI): use <a href="https://jbenet.github.io/hashpipe/">HashPipe</a>, which can output verified data
<li>Linux (CLI): use <code>sha256sum -b [file]</code>
<li>Mac OS X (CLI): use <code>shasum -b -a 256 [file]</code>
<li>Windows (CLI): use <a href="https://www.microsoft.com/en-us/download/details.aspx?id=11533">Microsoft File Checksum Integrity Verifier</a> (only supports SHA-1 and MD5)
<li>GUI apps: unknown
</ul>

<p><b>Are hashes actually secure?</b></p>
<p>If they use a good algorithm and are at least 16-24 bytes long, then yes.</p>

<p><b>Is it better to use even longer hashes like SHA-384 or SHA-512?</b></p>
<p>There are diminishing returns. Past a certain point, the length does not matter. I'm not qualified to comment on differences in the algorithms themselves, but SHA-256 is widely accepted.</p>
<p>You can check the probability tables for hash collisions yourself <a href="https://en.wikipedia.org/wiki/Birthday_problem#Probability_table">here</a>.</p>

<p><b>What do <sup>[#]</sup> links do?</b></p>
<p>Those provide the hash as a raw link, for formats that support it. In theory you could use it to resolve the hash through a different system. However, you need the appropriate protocol handler, and for now software support is mostly non-existant. My other project <a href="https://github.com/btrask/stronglink">StrongLink</a> has limited support, if you configure it. A big problem is <a href="https://html.spec.whatwg.org/#safelisted-scheme">the protocol safelist</a>, which makes it difficult for web apps to resolve hashes (see complaints <a href="https://github.com/jquery/standards/issues/12">here</a> and <a href="https://lists.w3.org/Archives/Public/public-whatwg-archive/2015Mar/0011.html">here</a>).</p>
<p>If you right click the <sup>[#]</sup> and choose "copy link," you'll get a link you can paste into a resolver (such as StrongLink) or chat/email.</p>

<p id="compat"><b>Why aren't the MultiHashes compatible with IPFS, or the Magnet URIs compatible with BitTorrent?</b></p>
<p>IPFS and BitTorrent compute their hashes in their own protocol-specific ways. BitTorrent hashes vary depending on the file name (amongst other things) and IPFS hashes vary depending on the chunker used. See my article, <a href="TODO">The Principles of Content Addressing</a>, or this <a href="https://github.com/ipfs/go-ipfs/issues/1953">IPFS bug report</a>. However, you can submit URLs from the <a href="TODO">ipfs.io gateway</a> to bridge between them.</p>

<p><b>Is there an API?</b></p>
<p>Not yet, but support is planned. For now, please use a <a href="./database.sql.gz">database snapshot</a>.</p>

<p><b>Can you add a new algorithm?</b></p>
<p>Yes, if: 1. the algorithm is relatively efficient, 2. it's in widespread use or in high demand, and 3. if there is a drop-in Node.js module we can use. Please check our <a href="https://github.com/btrask/hash-archive/issues">issues list</a> and open a new one if it hasn't been proposed already.</p>

<p><b>Why not use the Web of Trust?</b></p>
<p>This is a link in the Web of Trust.</p>

<p class="footer">Created by <a href="https://bentrask.com">Ben Trask</a> in association with <a href="https://archivelab.org">Archive Labs</a></p>
</div>

